from fastapi import APIRouter
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from kenopi_chatbot import generate_response, generate_advanced_response

router = APIRouter(prefix="/kenopi", tags=["Kenopi CS"])

class ChatMsg(BaseModel):
    role: str  # 'user' or 'bot'
    content: str

class ChatReq(BaseModel):
    messages: List[ChatMsg]
    # auto_modeëŠ” ì œê±° - í•­ìƒ ìë™ ëª¨ë“œ ì‚¬ìš©

class ChatResponse(BaseModel):
    response: str
    selected_mode: Optional[str] = None  # AIê°€ ì„ íƒí•œ ëª¨ë“œ í‘œì‹œ

class AdvancedChatResponse(BaseModel):
    response: str
    selected_mode: str
    complexity: Optional[str] = None
    question_type: Optional[str] = None
    urgency: Optional[str] = None
    quality_score: Optional[str] = None
    faq_matched: Optional[bool] = None
    auto_selection: bool = True

@router.post("/chat", response_model=ChatResponse)
async def kenopi_chat(req: ChatReq):
    """
    ì¼€ë…¸í”¼ CS ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸ (ìë™ ëª¨ë“œ ì„ íƒ)
    
    AIê°€ ì§ˆë¬¸ì˜ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ìµœì ì˜ ëª¨ë“œë¥¼ ì„ íƒí•©ë‹ˆë‹¤:
    - ê°„ë‹¨í•œ ì§ˆë¬¸ â†’ ê¸°ë³¸ ëª¨ë“œ (ë¹ ë¥¸ ì‘ë‹µ)
    - ë³´í†µ ì§ˆë¬¸ â†’ ì¶”ë¡  ëª¨ë“œ (ë‹¨ê³„ì  ì‚¬ê³ )
    - ë³µì¡í•œ ì§ˆë¬¸ â†’ ê³ ê¸‰ ëª¨ë“œ (ì¢…í•© ë¶„ì„)
    """
    # í•­ìƒ ìë™ ëª¨ë“œ ì‚¬ìš©
    reply = generate_response([m.dict() for m in req.messages], auto_mode=True)
    
    return ChatResponse(
        response=reply,
        selected_mode="auto"  # ìë™ ì„ íƒë¨ì„ í‘œì‹œ
    )

@router.post("/chat/advanced", response_model=AdvancedChatResponse)
async def kenopi_advanced_chat(req: ChatReq):
    """
    ìë™ ëª¨ë“œ ì„ íƒ + ìƒì„¸ ë¶„ì„ ì •ë³´ í¬í•¨ ì—”ë“œí¬ì¸íŠ¸
    
    AIê°€ ìë™ìœ¼ë¡œ ì„ íƒí•œ ëª¨ë“œì™€ ë¶„ì„ ê³¼ì •ì„ í•¨ê»˜ ì œê³µ:
    - selected_mode: AIê°€ ì„ íƒí•œ ëª¨ë“œ (basic/thinking/enhanced)
    - complexity: ì§ˆë¬¸ ë³µì¡ë„ (low/medium/high)
    - question_type: ì§ˆë¬¸ ìœ í˜• (greeting/inquiry/complaint/request)
    - urgency: ê¸´ê¸‰ë„ (low/medium/high)
    - quality_score: ì‘ë‹µ í’ˆì§ˆ ì ìˆ˜
    """
    result = generate_advanced_response([m.dict() for m in req.messages])
    
    return AdvancedChatResponse(
        response=result["response"],
        selected_mode=result.get("selected_mode", "basic"),
        complexity=result.get("complexity"),
        question_type=result.get("question_type"),
        urgency=result.get("urgency"),
        quality_score=result.get("quality_score"),
        faq_matched=result.get("faq_matched"),
        auto_selection=result.get("auto_selection", True)
    )

@router.get("/thinking/status")
async def get_thinking_status():
    """ìë™ ëª¨ë“œ ì„ íƒ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    try:
        from sequential_thinking_mcp import thinking_mcp
        
        return {
            "status": "active",
            "auto_mode_selection": {
                "enabled": True,
                "description": "AIê°€ ì§ˆë¬¸ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ìµœì  ëª¨ë“œ ì„ íƒ"
            },
            "available_modes": {
                "basic": {
                    "name": "ê¸°ë³¸ ëª¨ë“œ",
                    "description": "ê°„ë‹¨í•œ ì§ˆë¬¸, ì¸ì‚¬ë§, FAQ ë§¤ì¹­ ì‹œ ì‚¬ìš©",
                    "icon": "ğŸ’¬"
                },
                "thinking": {
                    "name": "ì¶”ë¡  ëª¨ë“œ", 
                    "description": "ë³´í†µ ë³µì¡ë„ ì§ˆë¬¸ì— ë‹¨ê³„ì  ì‚¬ê³  ì ìš©",
                    "icon": "ğŸ§ "
                },
                "enhanced": {
                    "name": "ê³ ê¸‰ ëª¨ë“œ",
                    "description": "ë³µì¡í•œ ë¬¸ì˜, ë¶ˆë§Œ, ê¸´ê¸‰ ìƒí™© ì‹œ ì¢…í•© ë¶„ì„",
                    "icon": "âš¡"
                }
            },
            "selection_criteria": {
                "complexity_analysis": ["high", "medium", "low"],
                "question_types": ["greeting", "inquiry", "complaint", "request"],
                "urgency_levels": ["high", "medium", "low"],
                "additional_factors": ["FAQ ë§¤ì¹­", "ëŒ€í™” ë§¥ë½", "ë¬¸ì¥ ê¸¸ì´"]
            },
            "sequential_thinking": {
                "available": thinking_mcp.mcp_available,
                "features": [
                    "ìë™ ë³µì¡ë„ ë¶„ì„",
                    "ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜",
                    "ê¸´ê¸‰ë„ íŒë‹¨",
                    "ëª¨ë“œ ìë™ ì„ íƒ",
                    "í’ˆì§ˆ ë³´ì¦ ì‹œìŠ¤í…œ"
                ]
            },
            "model_info": {
                "engine": "MCP Sequential Thinking Tools",
                "fallback": "GPT-3.5-turbo",
                "auto_selection": True
            }
        }
    except ImportError:
        return {
            "status": "limited",
            "auto_mode_selection": {
                "enabled": False,
                "description": "Sequential Thinking MCPê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ"
            },
            "available_modes": {
                "basic": {
                    "name": "ê¸°ë³¸ ëª¨ë“œ",
                    "description": "ê¸°ë³¸ ì‘ë‹µë§Œ ê°€ëŠ¥",
                    "icon": "ğŸ’¬"
                }
            }
        }

@router.post("/thinking/demo")
async def demo_auto_mode_selection(req: ChatReq):
    """
    ìë™ ëª¨ë“œ ì„ íƒ ë°ëª¨ (ì—¬ëŸ¬ ì§ˆë¬¸ ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸)
    """
    if not req.messages:
        return {"error": "ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤"}
    
    import time
    
    messages = [m.dict() for m in req.messages]
    query = messages[-1]["content"]
    
    # ìë™ ëª¨ë“œ ì„ íƒ ìƒì„¸ ë¶„ì„
    start_time = time.time()
    result = generate_advanced_response(messages)
    processing_time = time.time() - start_time
    
    # ë‹¤ë¥¸ ëª¨ë“œë“¤ê³¼ ë¹„êµë¥¼ ìœ„í•œ ê¸°ë³¸ ì‘ë‹µ
    basic_start = time.time()
    basic_response = generate_response(messages, auto_mode=False)
    basic_time = time.time() - basic_start
    
    return {
        "query": query,
        "auto_selection_result": {
            "selected_mode": result.get("selected_mode"),
            "complexity": result.get("complexity"),
            "question_type": result.get("question_type"),
            "urgency": result.get("urgency"),
            "reasoning": f"'{query}' ë¶„ì„ ê²°ê³¼ {result.get('complexity')} ë³µì¡ë„, {result.get('question_type')} ìœ í˜•ìœ¼ë¡œ íŒë‹¨ë˜ì–´ {result.get('selected_mode')} ëª¨ë“œê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤."
        },
        "responses": {
            "auto_selected": {
                "response": result["response"],
                "mode": result.get("selected_mode"),
                "processing_time": round(processing_time, 3),
                "quality_score": result.get("quality_score")
            },
            "basic_fallback": {
                "response": basic_response,
                "mode": "basic",
                "processing_time": round(basic_time, 3),
                "quality_score": "basic"
            }
        },
        "analysis": {
            "auto_selection_benefits": [
                "ì‚¬ìš©ìê°€ ëª¨ë“œë¥¼ ì„ íƒí•  í•„ìš” ì—†ìŒ",
                "ì§ˆë¬¸ì— ìµœì í™”ëœ ì‘ë‹µ ë°©ì‹ ìë™ ì ìš©",
                "ë³µì¡í•œ ì§ˆë¬¸ì— ë” ì‹ ì¤‘í•œ ë¶„ì„",
                "ê°„ë‹¨í•œ ì§ˆë¬¸ì— ë¹ ë¥¸ ì‘ë‹µ"
            ],
            "selection_factors": result.get("analysis", {}),
            "performance": {
                "auto_time": processing_time,
                "basic_time": basic_time,
                "intelligence_overhead": round(processing_time - basic_time, 3)
            }
        }
    }

@router.get("/thinking/examples")
async def get_auto_mode_examples():
    """ìë™ ëª¨ë“œ ì„ íƒ ì˜ˆì‹œë“¤"""
    return {
        "examples": [
            {
                "query": "ì•ˆë…•í•˜ì„¸ìš”",
                "expected_mode": "basic",
                "reason": "ê°„ë‹¨í•œ ì¸ì‚¬ë§ - ë¹ ë¥¸ ì‘ë‹µ"
            },
            {
                "query": "ë°°ì†¡ ê¸°ê°„ì´ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?",
                "expected_mode": "thinking",
                "reason": "ì¼ë°˜ì ì¸ ë¬¸ì˜ - ë‹¨ê³„ì  ì‚¬ê³ ë¡œ ì •í™•í•œ ë‹µë³€"
            },
            {
                "query": "ì œí’ˆì´ ë¶ˆëŸ‰ì¸ë° í™˜ë¶ˆê³¼ êµí™˜ ì¤‘ ì–´ë–¤ ê²Œ ë” ìœ ë¦¬í•œê°€ìš”?",
                "expected_mode": "enhanced", 
                "reason": "ë³µì¡í•œ ìƒí™© - ë‹¤ê°ë„ ë¶„ì„ í•„ìš”"
            },
            {
                "query": "ê¸‰í•˜ê²Œ ì²˜ë¦¬í•´ì£¼ì„¸ìš”! ì œí’ˆì— ë¬¸ì œê°€ ìˆì–´ìš”!",
                "expected_mode": "enhanced",
                "reason": "ê¸´ê¸‰ ìƒí™© + ë¶ˆë§Œ - ì‹ ì¤‘í•œ ëŒ€ì‘ í•„ìš”"
            },
            {
                "query": "ê°ì‚¬í•©ë‹ˆë‹¤",
                "expected_mode": "basic",
                "reason": "ê°„ë‹¨í•œ ê°ì‚¬ ì¸ì‚¬ - ê¸°ë³¸ ì‘ë‹µ"
            }
        ],
        "selection_logic": {
            "basic_mode": [
                "ì¸ì‚¬ë§ (ì•ˆë…•, ê°ì‚¬ ë“±)",
                "FAQ ë§¤ì¹­ë˜ëŠ” ê°„ë‹¨í•œ ì§ˆë¬¸",
                "ì§§ê³  ëª…í™•í•œ í™•ì¸ ì§ˆë¬¸"
            ],
            "thinking_mode": [
                "ì¼ë°˜ì ì¸ ë¬¸ì˜ ì‚¬í•­",
                "ì¤‘ê°„ ê¸¸ì´ì˜ ì§ˆë¬¸",
                "ì„¤ëª…ì´ í•„ìš”í•œ ë‚´ìš©"
            ],
            "enhanced_mode": [
                "ë³µì¡í•œ ìƒí™© ë¶„ì„ í•„ìš”",
                "ë¶ˆë§Œì´ë‚˜ ë¬¸ì œ ì œê¸°",
                "ê¸´ê¸‰ ìƒí™©",
                "ì—¬ëŸ¬ ì˜µì…˜ ë¹„êµ í•„ìš”"
            ]
        }
    } 